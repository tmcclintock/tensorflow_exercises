{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters of a Gaussian\n",
    "In this notebook I fit some data to find the parameters of a Gaussian used to generate that data. This is all pulled completely from Kyle Lo's post found here: http://kyleclo.github.io/maximum-likelihood-in-tensorflow-pt-1/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the true parameters\n",
    "TRUE_MU     = 10.\n",
    "TRUE_SIGMA  = 5.0\n",
    "SAMPLE_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the training data\n",
    "np.random.seed(0)\n",
    "x_obs = np.random.normal(loc  = TRUE_MU,\n",
    "                        scale = TRUE_SIGMA,\n",
    "                        size  = SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescale sub-obtimally. In reality one would use\n",
    "#the mean and standard deviation\n",
    "CENTER = x_obs.min()\n",
    "SCALE  = x_obs.max() - x_obs.min()\n",
    "x_obs = (x_obs - CENTER) / SCALE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we swtich from working with $\\sigma$ to working with the variance $\\phi=\\sigma^2$. This is to prevent the optimizer from going to negative standard deviations, but amounts to putting a prior on $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a PGM\n",
    "#Placeholder for the data\n",
    "x = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "INIT_MU_PARAMS  = {'loc': 0.0, 'scale':1.0}\n",
    "INIT_PHI_PARAMS = {'loc': 0.0, 'scale':1.0}\n",
    "RANDOM_SEED = 0\n",
    "\n",
    "#Parameters\n",
    "mu  = tf.Variable(initial_value=np.random.normal(**INIT_MU_PARAMS),\n",
    "                  dtype=tf.float32)\n",
    "phi = tf.Variable(initial_value=np.random.normal(**INIT_PHI_PARAMS),\n",
    "                  dtype=tf.float32)\n",
    "sigma = tf.square(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the loss function,\n",
    "gaussian_dist = tf.contrib.distributions.Normal(loc=mu, scale=sigma)\n",
    "log_prob = gaussian_dist.log_prob(value=x)\n",
    "neg_log_likelihood = -1.0 * tf.reduce_sum(log_prob)\n",
    "\n",
    "grad = tf.gradients(neg_log_likelihood, [mu, phi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the optimization scheme\n",
    "LEARNING_RATE = 0.001\n",
    "MAX_ITER = 10000\n",
    "TOL_PARAM, TOL_LOSS, TOL_GRAD = 1e-8, 1e-8, 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "train_op  = optimizer.minimize(loss=neg_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function convergence in 1202 iterations.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "    \n",
    "    i = 1\n",
    "    obs_mu, obs_phi, obs_sigma = sess.run(fetches=[[mu], [phi], [sigma]])\n",
    "    obs_loss = sess.run(fetches=[neg_log_likelihood], feed_dict={x: x_obs})\n",
    "    obs_grad = sess.run(fetches=[grad], feed_dict={x: x_obs})\n",
    "    \n",
    "    while True:\n",
    "        sess.run(fetches=train_op, feed_dict={x: x_obs})\n",
    "        \n",
    "        #update parameters\n",
    "        new_mu, new_phi, new_sigma = sess.run(fetches=[mu, phi, sigma])\n",
    "        diff_norm = np.linalg.norm(np.subtract([new_mu, new_phi],\n",
    "                                              [obs_mu[-1], obs_phi[-1]]))\n",
    "        #update loss\n",
    "        new_loss = sess.run(fetches=neg_log_likelihood, feed_dict={x: x_obs})\n",
    "        loss_diff = np.abs(new_loss - obs_loss[-1])\n",
    "        \n",
    "        #update gradient\n",
    "        new_grad = sess.run(fetches=grad, feed_dict={x: x_obs})\n",
    "        grad_norm = np.linalg.norm(new_grad)\n",
    "        \n",
    "        obs_mu.append(new_mu)\n",
    "        obs_phi.append(new_phi)\n",
    "        obs_sigma.append(new_sigma)\n",
    "        obs_loss.append(new_loss)\n",
    "        obs_grad.append(new_grad)\n",
    "        \n",
    "        if diff_norm < TOL_PARAM:\n",
    "            print('Parameter convergence in {} iterations.'.format(i))\n",
    "            break\n",
    "        if loss_diff < TOL_LOSS:\n",
    "            print('Loss function convergence in {} iterations.'.format(i))\n",
    "            break\n",
    "        if grad_norm < TOL_GRAD:\n",
    "            print('Gradient convergence in {} iterations.'.format(i))\n",
    "            break\n",
    "        if i >= MAX_ITER:\n",
    "            print('Max iterations reached without convergence.')\n",
    "            break\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Final parameters:', 0.54193175, 0.20898542)\n",
      "('True parameters: ', 0.5417657651097033, 0.20898520692791359)\n"
     ]
    }
   ],
   "source": [
    "final_mu = obs_mu[-1]\n",
    "final_sigma = obs_sigma[-1]\n",
    "print(\"Final parameters:\",final_mu, final_sigma)\n",
    "print(\"True parameters: \",np.mean(x_obs), np.std(x_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
