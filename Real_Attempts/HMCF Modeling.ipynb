{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow for $\\xi_{\\rm hm}$\n",
    "\n",
    "In The Aemulus Project, we have measured the halo-matter correlation function $\\xi_{\\rm hm}$ for many halo masses over a large range of physical scales. Because of this, we have a lot of training data from which to build an emulator. What we would like to do, is use a physical model that is flexible and fit it to each measured correlation function, thereby doing a dimensional reduction on the training parameters. The amount of training data for an individual Gaussian Processes will go down from $N_{\\rm sims} \\times N_{\\rm z} \\times N_{\\rm M} \\times N_{\\rm r}$ down to $N_{\\rm sims} \\times N_{\\rm z} \\times N_{\\rm M}$, or possibly less if we identify parameters that are simple functions of redshift $z$ or mass (or peak height $\\nu$). This represents a reduction by a factor of 50-1000, depending on the final fits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages of tensorflow\n",
    "\n",
    "The reason I'd like to use TF here is because of the quality of the optimizers implemented it has. The fit function parameters have unknown degeneracies with each other, are numerically at very different scales, and have units. Thus, I need a good affine-invariant optimizer, and so far I have found that Nelder-Mead doesn't cut it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to download the data!\n"
     ]
    }
   ],
   "source": [
    "#Load in correlation function data\n",
    "print(\"Need to download the data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load \"parameters\" that are already known, as well as extra data we need\n",
    "Mass = 999e9\n",
    "bias = 1.0 #from emulator\n",
    "redshift = 0.\n",
    "r_xi  = 0 #np.loadtxt(\"r.txt\")\n",
    "xi_mm = 0 #np.load(\"xi_mm_z%.2f.npy\"%redshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a PGM\n",
    "#Placeholders for the data and result\n",
    "xi_model = tf.placeholder(dtype=tf.float32) #will hold model CF\n",
    "xi_data  = tf.placeholder(dtype=tf.float32) #holds the measured CF\n",
    "Cinv     = tf.placeholder(dtype=tf.float32) #holds the inverse covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter guesses\n",
    "conc = tf.Variable(initial_value=np.random.normal(loc=1, scale=1), dtype=tf.float32)\n",
    "rt   = tf.Variable(initial_value=np.random.normal(loc=1, scale=1), dtype=tf.float32)\n",
    "bt   = tf.Variable(initial_value=np.random.normal(loc=1, scale=1), dtype=tf.float32)\n",
    "lnMa = tf.Variable(initial_value=np.random.normal(loc=1, scale=1), dtype=tf.float32)\n",
    "ca   = tf.Variable(initial_value=np.random.normal(loc=1, scale=1), dtype=tf.float32)\n",
    "lnMb = tf.Variable(initial_value=np.random.normal(loc=1, scale=1), dtype=tf.float32)\n",
    "cb   = tf.Variable(initial_value=np.random.normal(loc=1, scale=1), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT!\n",
    "\n",
    "We need to wrap the modeling function from the cluster_toolkit in a form that is [tf.py_func](https://www.tensorflow.org/api_docs/python/tf/py_func) compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xi_model = tf.pyfunc(ct.function, [my_input], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the session\n",
    "_ = \"\"\"\n",
    "with tf.Session() as sess:\n",
    "    sess.run(fetches=tf.global_variables_initializer())\n",
    "    \n",
    "    i = 1\n",
    "    obs_vars = sess.run(fetches=[[conc], [rt], [bt], \n",
    "                                 [lnMa], [ca], \n",
    "                                 [lnMb], [cb]])\n",
    "    obs_lnLike =- sess.run(fetches=[chi2], feed_dict={\"stuff\"})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
